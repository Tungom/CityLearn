{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BABY STEPS - Getting Started\n",
    "\n",
    "```\n",
    "Author: Chia E Tungom\n",
    "Email: bamtungom@protonmail.com\n",
    "```\n",
    "\n",
    "This Notebook demonstrates the basic facets of the CityLearn Environment. You can play with it to get familiar with the environment.\n",
    "Important aspects of the environment that covered include include:\n",
    "\n",
    "1. Observation Space (dataset)\n",
    "\n",
    "2. Action Space (discrete or continous)\n",
    "\n",
    "3. Model (Policy)\n",
    "\n",
    "4. Action (steps)\n",
    "\n",
    "5. Evaluation (reward)\n",
    "\n",
    "We use general purpose functions common to most RL environments for illustration.\n",
    "\n",
    "__Note:__ To run this notebook, place it in the root directory of your CityLearn Phase one repository (same directory as requirements.txt)\n",
    "\n",
    "__Lets Goooooo!!!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chemago/opt/anaconda3/envs/CityLearn/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# To run this example, move this file to the main directory of this repository\n",
    "from citylearn import CityLearn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from agents.marlisa import MARLISA\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Environment\n",
    "\n",
    "The first thing we need to do is create a CityLearn environment. The environment is defined using a json schema and dataset which can be found in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "climate_zone = 5\n",
    "params = {'data_path':Path(\"data/Climate_Zone_\"+str(climate_zone)), \n",
    "        'building_attributes':'building_attributes.json', \n",
    "        'weather_file':'weather_data.csv', \n",
    "        'solar_profile':'solar_generation_1kW.csv', \n",
    "        'carbon_intensity':'carbon_intensity.csv',\n",
    "        'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5,6,7,8,9]],\n",
    "        'buildings_states_actions':Path('buildings_state_action_space.json'), \n",
    "        'simulation_period': (0, 8760*4-1), \n",
    "        'cost_function': ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption','carbon_emissions'], \n",
    "        'central_agent': False,\n",
    "        'save_memory': False }\n",
    "\n",
    "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
    "# Can be obtained using observations_spaces[i].low or .high\n",
    "env = CityLearn(**params)\n",
    "observations_spaces, actions_spaces = env.get_state_action_spaces()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Building_1': {'building_type': 1,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 120,\n",
       "  'Annual_DHW_demand (kWh)': 11643.328,\n",
       "  'Annual_cooling_demand (kWh)': 619542.205,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 215850.522,\n",
       "  'Correlations_DHW': {'Building_2': 0.505,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.338,\n",
       "   'Building_6': 0.317,\n",
       "   'Building_7': 0.116,\n",
       "   'Building_8': 0.186,\n",
       "   'Building_9': 0.272},\n",
       "  'Correlations_cooling_demand': {'Building_2': 0.798,\n",
       "   'Building_3': 0.869,\n",
       "   'Building_4': 0.802,\n",
       "   'Building_5': 0.75,\n",
       "   'Building_6': 0.756,\n",
       "   'Building_7': 0.67,\n",
       "   'Building_8': 0.734,\n",
       "   'Building_9': 0.708},\n",
       "  'Correlations_non_shiftable_load': {'Building_2': 0.58,\n",
       "   'Building_3': 0.717,\n",
       "   'Building_4': 0.566,\n",
       "   'Building_5': 0.168,\n",
       "   'Building_6': 0.205,\n",
       "   'Building_7': -0.162,\n",
       "   'Building_8': 0.13,\n",
       "   'Building_9': 0.028}},\n",
       " 'Building_2': {'building_type': 2,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 0,\n",
       "  'Annual_DHW_demand (kWh)': 32752.16,\n",
       "  'Annual_cooling_demand (kWh)': 154191.935,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 73840.93,\n",
       "  'Correlations_DHW': {'Building_1': 0.505,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.079,\n",
       "   'Building_6': 0.098,\n",
       "   'Building_7': 0.123,\n",
       "   'Building_8': 0.121,\n",
       "   'Building_9': 0.113},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.798,\n",
       "   'Building_3': 0.869,\n",
       "   'Building_4': 0.811,\n",
       "   'Building_5': 0.903,\n",
       "   'Building_6': 0.889,\n",
       "   'Building_7': 0.84,\n",
       "   'Building_8': 0.882,\n",
       "   'Building_9': 0.866},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.58,\n",
       "   'Building_3': 0.861,\n",
       "   'Building_4': 0.856,\n",
       "   'Building_5': 0.512,\n",
       "   'Building_6': 0.458,\n",
       "   'Building_7': 0.03,\n",
       "   'Building_8': 0.214,\n",
       "   'Building_9': 0.173}},\n",
       " 'Building_3': {'building_type': 3,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 0,\n",
       "  'Annual_DHW_demand (kWh)': 0.0,\n",
       "  'Annual_cooling_demand (kWh)': 343516.855,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 54041.595,\n",
       "  'Correlations_DHW': {'Building_1': nan,\n",
       "   'Building_2': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': nan,\n",
       "   'Building_6': nan,\n",
       "   'Building_7': nan,\n",
       "   'Building_8': nan,\n",
       "   'Building_9': nan},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.869,\n",
       "   'Building_2': 0.869,\n",
       "   'Building_4': 0.948,\n",
       "   'Building_5': 0.819,\n",
       "   'Building_6': 0.806,\n",
       "   'Building_7': 0.72,\n",
       "   'Building_8': 0.799,\n",
       "   'Building_9': 0.762},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.717,\n",
       "   'Building_2': 0.861,\n",
       "   'Building_4': 0.936,\n",
       "   'Building_5': 0.39,\n",
       "   'Building_6': 0.356,\n",
       "   'Building_7': -0.081,\n",
       "   'Building_8': 0.198,\n",
       "   'Building_9': 0.117}},\n",
       " 'Building_4': {'building_type': 4,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 40,\n",
       "  'Annual_DHW_demand (kWh)': 0.0,\n",
       "  'Annual_cooling_demand (kWh)': 305195.842,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 35628.47,\n",
       "  'Correlations_DHW': {'Building_1': nan,\n",
       "   'Building_2': nan,\n",
       "   'Building_3': nan,\n",
       "   'Building_5': nan,\n",
       "   'Building_6': nan,\n",
       "   'Building_7': nan,\n",
       "   'Building_8': nan,\n",
       "   'Building_9': nan},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.802,\n",
       "   'Building_2': 0.811,\n",
       "   'Building_3': 0.948,\n",
       "   'Building_5': 0.768,\n",
       "   'Building_6': 0.748,\n",
       "   'Building_7': 0.667,\n",
       "   'Building_8': 0.752,\n",
       "   'Building_9': 0.713},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.566,\n",
       "   'Building_2': 0.856,\n",
       "   'Building_3': 0.936,\n",
       "   'Building_5': 0.435,\n",
       "   'Building_6': 0.373,\n",
       "   'Building_7': 0.003,\n",
       "   'Building_8': 0.245,\n",
       "   'Building_9': 0.204}},\n",
       " 'Building_5': {'building_type': 5,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 25,\n",
       "  'Annual_DHW_demand (kWh)': 33360.09,\n",
       "  'Annual_cooling_demand (kWh)': 219085.813,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 89096.15,\n",
       "  'Correlations_DHW': {'Building_1': 0.338,\n",
       "   'Building_2': 0.079,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_6': 0.794,\n",
       "   'Building_7': 0.393,\n",
       "   'Building_8': 0.543,\n",
       "   'Building_9': 0.71},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.75,\n",
       "   'Building_2': 0.903,\n",
       "   'Building_3': 0.819,\n",
       "   'Building_4': 0.768,\n",
       "   'Building_6': 0.976,\n",
       "   'Building_7': 0.95,\n",
       "   'Building_8': 0.965,\n",
       "   'Building_9': 0.96},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.168,\n",
       "   'Building_2': 0.512,\n",
       "   'Building_3': 0.39,\n",
       "   'Building_4': 0.435,\n",
       "   'Building_6': 0.512,\n",
       "   'Building_7': 0.277,\n",
       "   'Building_8': 0.258,\n",
       "   'Building_9': 0.331}},\n",
       " 'Building_6': {'building_type': 5,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 20,\n",
       "  'Annual_DHW_demand (kWh)': 33280.59,\n",
       "  'Annual_cooling_demand (kWh)': 225442.65,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 90840.2,\n",
       "  'Correlations_DHW': {'Building_1': 0.317,\n",
       "   'Building_2': 0.098,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.794,\n",
       "   'Building_7': 0.506,\n",
       "   'Building_8': 0.629,\n",
       "   'Building_9': 0.751},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.756,\n",
       "   'Building_2': 0.889,\n",
       "   'Building_3': 0.806,\n",
       "   'Building_4': 0.748,\n",
       "   'Building_5': 0.976,\n",
       "   'Building_7': 0.95,\n",
       "   'Building_8': 0.958,\n",
       "   'Building_9': 0.957},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.205,\n",
       "   'Building_2': 0.458,\n",
       "   'Building_3': 0.356,\n",
       "   'Building_4': 0.373,\n",
       "   'Building_5': 0.512,\n",
       "   'Building_7': 0.273,\n",
       "   'Building_8': 0.298,\n",
       "   'Building_9': 0.343}},\n",
       " 'Building_7': {'building_type': 5,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 0,\n",
       "  'Annual_DHW_demand (kWh)': 33335.01,\n",
       "  'Annual_cooling_demand (kWh)': 239796.967,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 118975.925,\n",
       "  'Correlations_DHW': {'Building_1': 0.116,\n",
       "   'Building_2': 0.123,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.393,\n",
       "   'Building_6': 0.506,\n",
       "   'Building_8': 0.757,\n",
       "   'Building_9': 0.648},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.67,\n",
       "   'Building_2': 0.84,\n",
       "   'Building_3': 0.72,\n",
       "   'Building_4': 0.667,\n",
       "   'Building_5': 0.95,\n",
       "   'Building_6': 0.95,\n",
       "   'Building_8': 0.935,\n",
       "   'Building_9': 0.947},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': -0.162,\n",
       "   'Building_2': 0.03,\n",
       "   'Building_3': -0.081,\n",
       "   'Building_4': 0.003,\n",
       "   'Building_5': 0.277,\n",
       "   'Building_6': 0.273,\n",
       "   'Building_8': 0.199,\n",
       "   'Building_9': 0.364}},\n",
       " 'Building_8': {'building_type': 5,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 0,\n",
       "  'Annual_DHW_demand (kWh)': 33253.29,\n",
       "  'Annual_cooling_demand (kWh)': 168048.793,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 63782.1,\n",
       "  'Correlations_DHW': {'Building_1': 0.186,\n",
       "   'Building_2': 0.121,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.543,\n",
       "   'Building_6': 0.629,\n",
       "   'Building_7': 0.757,\n",
       "   'Building_9': 0.721},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.734,\n",
       "   'Building_2': 0.882,\n",
       "   'Building_3': 0.799,\n",
       "   'Building_4': 0.752,\n",
       "   'Building_5': 0.965,\n",
       "   'Building_6': 0.958,\n",
       "   'Building_7': 0.935,\n",
       "   'Building_9': 0.982},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.13,\n",
       "   'Building_2': 0.214,\n",
       "   'Building_3': 0.198,\n",
       "   'Building_4': 0.245,\n",
       "   'Building_5': 0.258,\n",
       "   'Building_6': 0.298,\n",
       "   'Building_7': 0.199,\n",
       "   'Building_9': 0.775}},\n",
       " 'Building_9': {'building_type': 5,\n",
       "  'climate_zone': 5,\n",
       "  'solar_power_capacity (kW)': 0,\n",
       "  'Annual_DHW_demand (kWh)': 33273.93,\n",
       "  'Annual_cooling_demand (kWh)': 200522.557,\n",
       "  'Annual_nonshiftable_electrical_demand (kWh)': 95229.325,\n",
       "  'Correlations_DHW': {'Building_1': 0.272,\n",
       "   'Building_2': 0.113,\n",
       "   'Building_3': nan,\n",
       "   'Building_4': nan,\n",
       "   'Building_5': 0.71,\n",
       "   'Building_6': 0.751,\n",
       "   'Building_7': 0.648,\n",
       "   'Building_8': 0.721},\n",
       "  'Correlations_cooling_demand': {'Building_1': 0.708,\n",
       "   'Building_2': 0.866,\n",
       "   'Building_3': 0.762,\n",
       "   'Building_4': 0.713,\n",
       "   'Building_5': 0.96,\n",
       "   'Building_6': 0.957,\n",
       "   'Building_7': 0.947,\n",
       "   'Building_8': 0.982},\n",
       "  'Correlations_non_shiftable_load': {'Building_1': 0.028,\n",
       "   'Building_2': 0.173,\n",
       "   'Building_3': 0.117,\n",
       "   'Building_4': 0.204,\n",
       "   'Building_5': 0.331,\n",
       "   'Building_6': 0.343,\n",
       "   'Building_7': 0.364,\n",
       "   'Building_8': 0.775}}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
    "building_info = env.get_building_information()\n",
    "building_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OBSERVATION SPACE\n",
    "\n",
    "The observation space is the data of the environment. This is what the agent sees inorder to decide which action to take.\n",
    "\n",
    "In the observation space, we see there are 9 different observations corresponding to the 9 buildings. For each building, the observation space is a 1x28 dimensional array of type float\n",
    "\n",
    "1. Use `env.get_state_action_spaces()[0]` to explore the properties of the environment. Index 0 stands for the observation space\n",
    "2. Use `env.get_state_action_spaces()[0].sample()` to see a sample observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([ 1.    1.    1.   -4.15 -4.41 -4.72 -5.34 14.38 14.33 14.29 14.19  0.\n",
      " -0.    0.    0.    0.   -0.    0.    0.   16.8  11.17  7.42  0.    0.\n",
      "  0.    0.    0.    0.  ], [1.2000000e+01 8.0000000e+00 2.4000000e+01 3.6700001e+01 3.6970001e+01\n",
      " 3.7279999e+01 3.7910000e+01 1.0000000e+02 1.0250000e+02 1.0500000e+02\n",
      " 1.0999000e+02 4.9162000e+02 5.0142001e+02 5.1122000e+02 5.3081000e+02\n",
      " 1.2126200e+03 1.2308300e+03 1.2532200e+03 1.2979900e+03 2.6379999e+01\n",
      " 9.2389999e+01 7.0910004e+01 9.9999962e+01 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 3.3668436e+02 6.8709970e-01], (28,), float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.65421915e+00,  7.93409348e+00,  6.29955769e+00,  2.02119331e+01,\n",
       "        2.79655533e+01,  2.42183056e+01, -5.20351791e+00,  4.98451920e+01,\n",
       "        1.00471237e+02,  3.41179314e+01,  5.04825516e+01,  1.70586945e+02,\n",
       "        1.17957466e+02,  1.46562485e+02,  4.56233795e+02,  1.01897644e+03,\n",
       "        3.45226166e+02,  5.23505493e+02,  1.14603259e+03,  1.68150330e+01,\n",
       "        3.47147331e+01,  5.51451302e+01,  2.04869328e+01,  8.36130142e-01,\n",
       "        5.89760303e-01,  9.75291967e-01,  3.23234528e+02,  5.44102907e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation  = env.get_state_action_spaces()[0]\n",
    "\n",
    "print(observation[0])\n",
    "observation[0].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Lower and Upperboud of a given observation\n",
    "\n",
    "You can get the upper and lower bounds of a buildigs observation space by running take the observation space of the building and using the method `high` or `low` respectively\n",
    "\n",
    "you can further index to get the high or low for a particular observation by adding  the index of the observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2000000e+01 8.0000000e+00 2.4000000e+01 3.6700001e+01 3.6970001e+01\n",
      " 3.7279999e+01 3.7910000e+01 1.0000000e+02 1.0250000e+02 1.0500000e+02\n",
      " 1.0999000e+02 4.9162000e+02 5.0142001e+02 5.1122000e+02 5.3081000e+02\n",
      " 1.2126200e+03 1.2308300e+03 1.2532200e+03 1.2979900e+03 2.6379999e+01\n",
      " 9.2389999e+01 7.0910004e+01 9.9999962e+01 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 3.3668436e+02 6.8709970e-01]\n",
      "[ 1.    1.    1.   -4.15 -4.41 -4.72 -5.34 14.38 14.33 14.29 14.19  0.\n",
      " -0.    0.    0.    0.   -0.    0.    0.   16.8  11.17  7.42  0.    0.\n",
      "  0.    0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(env.get_state_action_spaces()[0][0].high)\n",
    "print(env.get_state_action_spaces()[0][0].low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION SPACE for Builiding ONE is Box([ 1.    1.    1.   -4.15 -4.41 -4.72 -5.34 14.38 14.33 14.29 14.19  0.\n",
      " -0.    0.    0.    0.   -0.    0.    0.   16.8  11.17  7.42  0.    0.\n",
      "  0.    0.    0.    0.   18.91  7.01  1.92  0.    0.    0.    0.    0.\n",
      " 17.36 13.69  1.77  0.    0.    0.    0.   16.83  9.27  0.44  0.    0.\n",
      "  0.    0.    0.   21.48 10.18  3.3   0.    0.    0.    0.    0.   22.\n",
      " 11.73  3.2   0.    0.    0.    0.    0.   21.47 10.57  3.7   0.    0.\n",
      "  0.    0.    0.   22.41 10.17  2.6   0.    0.    0.    0.    0.   22.29\n",
      " 10.16  4.6   0.    0.    0.    0.    0.  ], [1.2000000e+01 8.0000000e+00 2.4000000e+01 3.6700001e+01 3.6970001e+01\n",
      " 3.7279999e+01 3.7910000e+01 1.0000000e+02 1.0250000e+02 1.0500000e+02\n",
      " 1.0999000e+02 4.9162000e+02 5.0142001e+02 5.1122000e+02 5.3081000e+02\n",
      " 1.2126200e+03 1.2308300e+03 1.2532200e+03 1.2979900e+03 2.6379999e+01\n",
      " 9.2389999e+01 7.0910004e+01 9.9999962e+01 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 3.3668436e+02 6.8709970e-01 2.8830000e+01 7.1610001e+01\n",
      " 1.4070000e+01 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0794250e+02 2.5290001e+01 9.0180000e+01 1.0740000e+01 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 2.1908000e+02 2.7400000e+01 9.6739998e+01\n",
      " 8.0600004e+00 3.3333321e+01 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 2.4136928e+02 2.4709999e+01 8.0269997e+01 3.1700001e+01 2.0833324e+01\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.8859276e+01 2.4500000e+01\n",
      " 7.4919998e+01 3.0600000e+01 1.6666660e+01 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 9.2525238e+01 2.3799999e+01 7.3489998e+01 2.9299999e+01\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.1616000e+02\n",
      " 2.4990000e+01 8.1180000e+01 3.0200001e+01 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 9.8699997e+01 2.5150000e+01 7.7169998e+01\n",
      " 3.1600000e+01 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 9.4250000e+01], (91,), float32)\n",
      "SAMPLE OBSERVATION SPACE for Builiding (array([2.1383135e+00, 5.0402384e+00, 1.4176186e+01, 1.2116372e+01,\n",
      "       3.6414085e+01, 8.2897348e+00, 2.9935867e+01, 4.7627415e+01,\n",
      "       5.7339352e+01, 6.2386917e+01, 7.0273186e+01, 4.3706979e+02,\n",
      "       4.3985483e+02, 2.3489224e+02, 4.4506296e+02, 4.6064264e+02,\n",
      "       6.8537714e+02, 3.2495825e+02, 6.0222778e+02, 2.3028013e+01,\n",
      "       1.6485828e+01, 3.3490231e+01, 3.0912192e+00, 6.8765467e-01,\n",
      "       1.9814236e-01, 4.5130119e-01, 1.8982617e+02, 3.8661519e-01,\n",
      "       2.6893929e+01, 1.8577023e+01, 5.2752252e+00, 0.0000000e+00,\n",
      "       4.6350044e-01, 1.3347170e-01, 5.7762218e-01, 9.6915283e+01,\n",
      "       2.3993761e+01, 8.8131813e+01, 5.8050199e+00, 0.0000000e+00,\n",
      "       7.0385027e-01, 8.2005143e-01, 1.8937804e+02, 2.4831722e+01,\n",
      "       5.6915840e+01, 6.8665199e+00, 3.3261738e+01, 5.3849679e-01,\n",
      "       4.6183386e-01, 6.3208044e-01, 6.4737312e+01, 2.1663315e+01,\n",
      "       7.0297318e+01, 1.0657663e+01, 9.1467991e+00, 1.7563224e-01,\n",
      "       9.1586864e-01, 8.3789563e-01, 2.9745811e+01, 2.3476694e+01,\n",
      "       4.6728313e+01, 2.7885786e+01, 1.2344802e+01, 9.8030853e-01,\n",
      "       2.2719275e-02, 3.2025617e-01, 7.8160683e+01, 2.1602385e+01,\n",
      "       1.8476509e+01, 2.8228151e+01, 0.0000000e+00, 9.9644548e-01,\n",
      "       3.9601189e-01, 3.5655107e-02, 7.6438797e+01, 2.2678102e+01,\n",
      "       1.8216913e+01, 1.6598364e+01, 0.0000000e+00, 2.1531151e-01,\n",
      "       1.5271473e-01, 3.2793480e-01, 6.9096352e+01, 2.3632774e+01,\n",
      "       2.2594738e+01, 1.7595272e+01, 0.0000000e+00, 5.9402168e-01,\n",
      "       6.2586749e-01, 1.5755759e-01, 9.2876152e+01], dtype=float32), 91)\n"
     ]
    }
   ],
   "source": [
    "# Using the normal gym environment commands dont make sense in these case\n",
    "print(f'OBSERVATION SPACE for Builiding ONE is {env.observation_space}')\n",
    "print(f'SAMPLE OBSERVATION SPACE for Builiding {env.observation_space.sample(), len(env.observation_space.sample())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ACTION SPACE\n",
    "\n",
    "This shows us the type of actions we can take along with the dimension and property (discrete of contineous) of each actions. \n",
    "\n",
    "The action space in citylearn is a 1x3 array. where there are 3 distinct continous action each in a given range.\n",
    "\n",
    "- Based on our environment, the action space for each building a 1x3 array.\n",
    "- one array is of the form `([lower bounds],[upper bounds], (3,), float32)` which correspond to `[(lower bound, upper bound), (dimension,), datatype]`\n",
    "- __lower bound__ is the lowest or smallest value of an action while __upper bound__ is the highest. The values in the index of lowerbound and upperboud correspond to a lower and upper bound of a given action\n",
    "- Dimension stands for  of our action which here is 3 (use `env.get_state_action_spaces()[1][0].sample()` to see an action). `env.get_state_action_spaces()[1]` is the action space and `env.get_state_action_spaces()[1][0]` is the action space of building 1.\n",
    "- Datatype is the data type of our action which here is float\n",
    "\n",
    "The actions that can be taken in a building include \n",
    "- __\"cooling_storage\"__: Index 1, \n",
    "- __\"dhw_storage\"__: Index 2, \n",
    "- __\"electrical_storage\"__: index 3\n",
    "\n",
    "__Note: Buildings have different set of actions e.g__\n",
    "- _for building 3 and 4 {\"cooling_storage\": true, \"dhw_storage\": false, \"electrical_storage\": true}, only cooling and electrical storage are available_\n",
    "- Therefore their action spaces are two dimensional with the first index and second index corresponding to cooling and electrical storage respectively \n",
    "\n",
    "The cell below illustrates the action space(s). Play with it for understanding the actions.\n",
    "\n",
    "`actions_spaces[0].sample()` produces a random action for building 1\n",
    "\n",
    "Note: You must pick an action space of a given building inorder to sample (use index e.g `actions_spaces[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Box([-0.5 -0.5 -1. ], [0.5 0.5 1. ], (3,), float32), Box([-0.33333334 -0.33333334 -1.        ], [0.33333334 0.33333334 1.        ], (3,), float32), Box([-0.5 -1. ], [0.5 1. ], (2,), float32), Box([-0.6666667 -1.       ], [0.6666667 1.       ], (2,), float32), Box([-0.2857143 -0.6666667 -1.       ], [0.2857143 0.6666667 1.       ], (3,), float32), Box([-0.6666667  -0.33333334 -1.        ], [0.6666667  0.33333334 1.        ], (3,), float32), Box([-0.5 -0.5 -1. ], [0.5 0.5 1. ], (3,), float32), Box([-0.33333334 -0.33333334 -1.        ], [0.33333334 0.33333334 1.        ], (3,), float32), Box([-0.33333334 -0.33333334 -1.        ], [0.33333334 0.33333334 1.        ], (3,), float32)]\n",
      " Sample Action for building 0 is >>> [-0.10754889 -0.39910504  0.8946236 ]\n",
      " Sample Action for building 1 is >>> [-0.04923359 -0.30237332 -0.15773708]\n",
      " Sample Action for building 2 is >>> [0.35133678 0.46253598]\n",
      " Sample Action for building 3 is >>> [-0.44977948  0.6696908 ]\n",
      " Sample Action for building 4 is >>> [-0.18628004  0.50580305  0.9473721 ]\n",
      " Sample Action for building 5 is >>> [ 0.01071647  0.06264323 -0.2673421 ]\n",
      " Sample Action for building 6 is >>> [-0.4897456   0.39113867 -0.83358467]\n",
      " Sample Action for building 7 is >>> [-0.19804634  0.24758466  0.80682427]\n",
      " Sample Action for building 8 is >>> [ 0.13938874 -0.07194242 -0.06502581]\n"
     ]
    }
   ],
   "source": [
    "actions_spaces  = env.get_state_action_spaces()[1]\n",
    "\n",
    "print(actions_spaces)\n",
    "\n",
    "for building in range(9):\n",
    "    print(f' Sample Action for building {building} is >>> { actions_spaces[building].sample()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ACTION SPACES Box([-0.5        -0.5        -1.         -0.33333334 -0.33333334 -1.\n",
      " -0.5        -1.         -0.6666667  -1.         -0.2857143  -0.6666667\n",
      " -1.         -0.6666667  -0.33333334 -1.         -0.5        -0.5\n",
      " -1.         -0.33333334 -0.33333334 -1.         -0.33333334 -0.33333334\n",
      " -1.        ], [0.5        0.5        1.         0.33333334 0.33333334 1.\n",
      " 0.5        1.         0.6666667  1.         0.2857143  0.6666667\n",
      " 1.         0.6666667  0.33333334 1.         0.5        0.5\n",
      " 1.         0.33333334 0.33333334 1.         0.33333334 0.33333334\n",
      " 1.        ], (25,), float32)\n",
      " ACTION SPACE for Builiding is [-0.1834386   0.01785553  0.34468722  0.32285252  0.05876467 -0.016072\n",
      "  0.3878966   0.40696472  0.5071004   0.8418417  -0.08242489 -0.6341966\n",
      " -0.74125296  0.25694144 -0.13599339 -0.6389603  -0.43374893  0.16214001\n",
      " -0.38510537 -0.05827567  0.19372386 -0.8778577   0.01835014  0.11552128\n",
      " -0.8877348 ]\n"
     ]
    }
   ],
   "source": [
    "# Using the normal gym environment commands dont make sense in this case\n",
    "\n",
    "print(f' ACTION SPACES {env.action_space}')\n",
    "print(f' ACTION SPACE for Builiding is {env.action_space.sample()}')\n",
    "\n",
    "# sample some actions\n",
    "# for action in range(5):\n",
    "#     print(f' SAMPLE ACTION SPACE for Builiding ONE >>> {env.action_space[1].sample()}')\n",
    "\n",
    "# we can observe the actions are continous in the range [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define A Model or Agent \n",
    "\n",
    "The agent is the Policy which decides what action to take given an observation. We can use Rule based actions(agents). The CityLearn setting is built for multiagent systems but a single agent can aslo be used.\n",
    "\n",
    "Here we just show how to load an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.sac import SAC\n",
    "\n",
    "# SAC??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TAKING AN ACTION\n",
    "\n",
    "As already explained with the action spaces, $n$ buildings will have $n$ actions with each action corresponding to one building. Therefore our actions should appear as follows\n",
    "\n",
    "- Action should be a List containing List(number of buildings). inside the list is a list conatining the actions corresponding to the action to be taken for a given building\n",
    "- Example for a five buildings environment, we could have.\n",
    "- The first, second and third action for each building corresponds to cooling, dhw and hot water respectively.\n",
    "\n",
    "``` python\n",
    "\n",
    "Actions = [ [0.0, 0.0, 0.0 ], [0.0, 0.0, 0.0 ],  ... , [0.0, 0.0, 0.0 ] ]\n",
    "\n",
    "```\n",
    "\n",
    "We take an action when we want to move one step ahead. We can do this using `env.step(action)`\n",
    "\n",
    "When we take an action the output contains a tuple with the following:\n",
    "\n",
    "1. Next State: Returns 9 arrays each corresponding to a building's next state (index order)\n",
    "2. Reward: An with nine values each corresponding to reward for one building (index order)\n",
    "3. If the state is a Terminal State\n",
    "4. Information about the environment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WE are about to take [list([-0.803533978392067, -0.9708785736040213, 0.00045900101177709374])\n",
      " list([-0.5002960863123926, 0.649633845235247, 0.7087104432107385])\n",
      " list([-0.1746678411131779, 0.6681019390379295])\n",
      " list([0.8481027891329702, -0.47712984075921194])\n",
      " list([-0.2944183629306081, -0.8662764001969054, -0.6632250024315305])\n",
      " list([0.3332782476124221, 0.8911335169033676, 0.3679087609471774])\n",
      " list([-0.3066792464312331, -0.9133752116445204, -0.5697539264524627])\n",
      " list([-0.5628983225272679, -0.6545682089841969, -0.23888611504349977])\n",
      " list([-0.6102541963285941, 0.5641690830147785, -0.26051513377919533])] \n",
      "\n",
      " NEXT STATE \n",
      " [array([ 1.00000000e+00,  8.00000000e+00,  2.00000000e+00,  7.61000000e+00,\n",
      "         9.92000000e+00,  1.47200000e+01,  1.30300000e+01,  9.30000000e+01,\n",
      "         9.36200000e+01,  8.85800000e+01,  1.01620000e+02,  0.00000000e+00,\n",
      "         1.67700000e+01,  1.12240000e+02,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.11000000e+00,  2.04000000e+00, -0.00000000e+00,  1.88200000e+01,\n",
      "         7.79700000e+01,  1.04100000e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  4.18169824e-04,  9.85030000e+00,  5.43740757e-01])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  22.57      ,\n",
      "         33.34      ,   1.92      ,   0.        ,   0.        ,\n",
      "          0.33333333,   0.56714946,  60.2604    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  19.79      ,\n",
      "         62.21      ,   1.77      ,   0.        ,   0.        ,\n",
      "          0.45450126,  21.77      ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  20.16      ,\n",
      "         59.61      ,   0.44      ,   0.        ,   0.84810279,\n",
      "          0.        ,   0.        ,  16.7051    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  21.78      ,\n",
      "         52.9       ,   7.2       ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  15.1138    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  22.54      ,\n",
      "         51.02      ,   7.6       ,   0.        ,   0.33327825,\n",
      "          0.31392694,   0.34360241,  62.3716    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  22.55      ,\n",
      "         47.61      ,  16.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  19.9512    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  22.71      ,\n",
      "         51.86      ,   5.4       ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  14.3213    ,   0.54374076])\n",
      " array([  1.        ,   8.        ,   2.        ,   7.61      ,\n",
      "          9.92      ,  14.72      ,  13.03      ,  93.        ,\n",
      "         93.62      ,  88.58      , 101.62      ,   0.        ,\n",
      "         16.77      , 112.24      ,   0.        ,   0.        ,\n",
      "          1.11      ,   2.04      ,  -0.        ,  22.84      ,\n",
      "         50.65      ,   7.9       ,   0.        ,   0.        ,\n",
      "          0.31690141,   0.        ,  51.7437    ,   0.54374076])] \n",
      "\n",
      " REWARDS [-955.7589, -218824.53, -10317.52, -4661.7305, -3452.3992, -242639.05, -7941.5835, -2937.2932, -138539.11] \n",
      "\n",
      " TERMINAL OR NOT >> False \n",
      "\n",
      " INFO {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chemago/opt/anaconda3/envs/CityLearn/lib/python3.7/site-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# print(env_reset(env)[\"action_space\"])\n",
    "# env_reset(env)[\"observation_space\"]\n",
    "# env.reset()[0]\n",
    "env.reset()\n",
    "import random\n",
    "Actions = [([random.uniform(-1,1) for _ in range(3)]) for _ in range(9)]\n",
    "\n",
    "#------------------generate random actions for each building -----------\n",
    "Actions = []\n",
    "for buildinG in range(1,10):\n",
    "    if (buildinG == 3) or (buildinG == 4):\n",
    "        # print(\" IN building \", buildinG)\n",
    "        Actions.append([random.uniform(-1,1) for _ in range(2)])\n",
    "    else:\n",
    "        # print(\" IN building \", buildinG)\n",
    "        Actions.append([random.uniform(-1,1) for _ in range(3)])\n",
    "\n",
    "Actions = np.array(Actions)\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "print(f' WE are about to take {Actions} \\n')\n",
    "next_state, reward, terminal, info = env.step(Actions)\n",
    "\n",
    "print(f' NEXT STATE \\n {next_state} \\n')\n",
    "print(f' REWARDS {reward} \\n')\n",
    "print(f' TERMINAL OR NOT >> {terminal} \\n')\n",
    "print(f' INFO {info}')\n",
    "\n",
    "# obs_dict = env_reset(env)\n",
    "# agent = OrderEnforcingAgent()\n",
    "# print(agent.register_reset(obs_dict))\n",
    "# env.step(agent.register_reset(obs_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluating Actions\n",
    "\n",
    "After Taking actions we can evaluate the performance of our agent or agents. The Final evaluation can only be done after steps are completed.\n",
    "for one interation, we can only see the reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2k/08x7pcb100l_zwn70_wbm3w40000gn/T/ipykernel_26737/1820614345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/Projects/EnergyManagemet/CityLearn/citylearn.py\u001b[0m in \u001b[0;36mcost\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# Average of all the daily peaks of the 365 day of the year. The peaks are calculated using the net energy demand of the whole district of buildings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'average_daily_peak'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_electric_consumption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_electric_consumption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_rbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m             \u001b[0mc_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Projects/EnergyManagemet/CityLearn/citylearn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# Average of all the daily peaks of the 365 day of the year. The peaks are calculated using the net energy demand of the whole district of buildings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'average_daily_peak'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_electric_consumption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_electric_consumption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_rbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m             \u001b[0mc_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_daily_peak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "env.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE RUN or LOCAL EVALUATION\n",
    "\n",
    "Some modification have been made from the origial code. For isinstance\n",
    "\n",
    "- We can run a test for a month i.e $30*24$ to quickly evaluate our agent \n",
    "\n",
    "we add the following code in the evaluation section \n",
    "\n",
    "``` python \n",
    "\n",
    "    # Skipping to shorten training time\n",
    "    days = 30*5\n",
    "    training_steps = 24*days\n",
    "    skipping = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/chemago/opt/anaconda3/envs/CityLearn/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if sys.path[0] == '':\n",
      "100%|██████████| 1/1 [07:18<00:00, 438.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'ramping': 3.6079023, '1-load_factor': 1.371217217793463, 'average_daily_peak': 1.5311601, 'peak_demand': 1.425577, 'net_electricity_consumption': 1.067433, 'carbon_emissions': 1.0771184, 'total': 1.6800680105471608, 'coordination_score': 1.9839641667282577}, {'ramping_last_yr': 3.5773516, '1-load_factor_last_yr': 1.3675885944909316, 'average_daily_peak_last_yr': 1.5559206, 'peak_demand_last_yr': 1.4492459, 'net_electricity_consumption_last_yr': 1.0673436, 'carbon_emissions_last_yr': 1.0795386, 'coordination_score_last_yr': 1.9875266738073643, 'total_last_yr': 1.726359363633722})\n",
      "Loss - ({'ramping': 3.6079023, '1-load_factor': 1.371217217793463, 'average_daily_peak': 1.5311601, 'peak_demand': 1.425577, 'net_electricity_consumption': 1.067433, 'carbon_emissions': 1.0771184, 'total': 1.6800680105471608, 'coordination_score': 1.9839641667282577}, {'ramping_last_yr': 3.5773516, '1-load_factor_last_yr': 1.3675885944909316, 'average_daily_peak_last_yr': 1.5559206, 'peak_demand_last_yr': 1.4492459, 'net_electricity_consumption_last_yr': 1.0673436, 'carbon_emissions_last_yr': 1.0795386, 'coordination_score_last_yr': 1.9875266738073643, 'total_last_yr': 1.726359363633722}) Simulation time (min) - 7.301432200272878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------Define Random Action function---------------------------------\n",
    "def randomActs():\n",
    "    Actions = []\n",
    "    for buildinG in range(1,10):\n",
    "        if (buildinG == 3) or (buildinG == 4):\n",
    "            # print(\" IN building \", buildinG)\n",
    "            Actions.append([random.uniform(-1,1) for _ in range(2)])\n",
    "        else:\n",
    "            # print(\" IN building \", buildinG)\n",
    "            Actions.append([random.uniform(-1,1) for _ in range(3)])\n",
    "\n",
    "    return np.array(Actions)\n",
    "\n",
    "\n",
    "#-------------Train----------------------------------------------------------\n",
    "n_episodes = 1\n",
    "Days = 10000\n",
    "# Skipping to shorten training time\n",
    "training_steps = 24*Days\n",
    "\n",
    "start = time.time()\n",
    "for e in tqdm(range(n_episodes)): \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    skipping = True\n",
    "    moves = 0  \n",
    "\n",
    "    while (not done) and skipping:\n",
    "        next_state, reward, done, _ = env.step(randomActs())\n",
    "        state = next_state\n",
    "        moves += 1\n",
    "        try:\n",
    "            print(env.cost())\n",
    "        except:\n",
    "            pass\n",
    "        # print(done, skipping)\n",
    "        if moves >= training_steps:\n",
    "            # print(\" TERMINATING AT SET STEP \", episode)\n",
    "            skipping = False\n",
    "        \n",
    "    print('Loss -',env.cost(), 'Simulation time (min) -',(time.time()-start)/60.0)\n",
    "    # CPU training for 603mins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ramping': 3.7272313,\n",
       "  '1-load_factor': 1.3625216173050632,\n",
       "  'average_daily_peak': 1.5394294,\n",
       "  'peak_demand': 1.3857098,\n",
       "  'net_electricity_consumption': 1.0712593,\n",
       "  'carbon_emissions': 1.0811657,\n",
       "  'total': 1.6945528336186844,\n",
       "  'coordination_score': 2.0037230175464806},\n",
       " {'ramping_last_yr': 3.7011318,\n",
       "  '1-load_factor_last_yr': 1.358140732676143,\n",
       "  'average_daily_peak_last_yr': 1.5539014,\n",
       "  'peak_demand_last_yr': 1.566414,\n",
       "  'net_electricity_consumption_last_yr': 1.0716972,\n",
       "  'carbon_emissions_last_yr': 1.0840944,\n",
       "  'coordination_score_last_yr': 2.044896996475844,\n",
       "  'total_last_yr': 1.768610946094414})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARLISA\n",
    "\n",
    "The MARLISA Algorithm takes inputs that can be classified into two categories\n",
    "\n",
    "### 1. Environment Parameters\n",
    "\n",
    "These are parameters specific to the reinforcement learning environment. They give information about the simulation envrionment that will be used. details about these environmental variables are explored above. A summary explanation can be laid down as follows.\n",
    "\n",
    "- __'building_ids':__ These are the building number and include written in the form `\"Building_id\"` where id is a building number a building_id can look as follows\n",
    "    - `[\"Building_1\", \"Building_2\", ... , \"Building_n\"]`\n",
    "- __'buildings_states_actions':__ This is a json file defining the different states and actions possible for a building e.g If a building has a \n",
    "    - `states {day :  False,  temp: True}` it means there will be information for temp but not for day\n",
    "    - `\"actions\": {\"cooling_storage\": true, \"dhw_storage\": true, \"electrical_storage\": false}`. this means there will be no action required or electric storage is absent in the building\n",
    "- __'building_info':__ Gives valuable information about a building like (not given in 2022)\n",
    "    - `building_type`\n",
    "    - `climate_zone`\n",
    "    - `solar_power_capacity (kW)`\n",
    "    - `Annual_DHW_demand (kWh)`\n",
    "    - `Annual_cooling_demand (kWh)`\n",
    "    - `Annual_nonshiftable_electrical_demand (kWh)`\n",
    "    - `etc`\n",
    "- __'observation_spaces':__ This is information about the observation space of every building in the environment. \n",
    "    - It contains n arrays where n is the number of buildings\n",
    "    - Each array contains the lower and upper bound for the building observation along with it's dimension and datatype\n",
    "- __'action_spaces':__ This is information about the actions_spaces of every building in the environment\n",
    "    - It contains n arrays where n is the number of buildings\n",
    "    - Each array contains the lower and upper bound for the building action along with it's dimension and datatype\n",
    "\n",
    "\n",
    "### 2. Algorithm Parameters\n",
    "\n",
    "These are parameters specific to our reinforcement learning algorithm. Details about these parameters can be found in the paper\n",
    "\n",
    "- `hidden_dim`:[256,256], \n",
    "- `discount`:0.99, \n",
    "- `tau`:5e-3, \n",
    "- `lr`:3e-4, \n",
    "- `batch_size`:256, \n",
    "- `replay_buffer_capacity`:1e5, \n",
    "- `regression_buffer_capacity`:3e4, \n",
    "- `start_training`:600, # Start updating actor-critic networks\n",
    "- `exploration_period`:7500, # Just taking random actions\n",
    "- `start_regression`:500, # Start training the regression model\n",
    "- `information_sharing`:True, # If True -> set the appropriate 'reward_function_ma' in reward_function.py\n",
    "- `pca_compression`:.95, \n",
    "- `action_scaling_coef`:0.5, # Actions are multiplied by this factor to prevent too aggressive actions\n",
    "- `reward_scaling`:5., # Rewards are normalized and multiplied by this factor\n",
    "- `update_per_step`:2, # How many times the actor-critic networks are updated every hourly time-step\n",
    "- `iterations_as`:2,# Iterations of the iterative action selection (see MARLISA paper for more info)\n",
    "- `safe_exploration`:True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARLISA CODE Line By Line\n",
    "\n",
    "## 1. Initialization (__init__ body) \n",
    "\n",
    "`[Line 58 to 65]` abstract information to individual buildings\n",
    "\n",
    "```python\n",
    "        self.action_list_ = []\n",
    "        self.action_list2_ = []\n",
    "        \n",
    "        self.time_step = 0\n",
    "        self.pca_flag = {uid : 0 for uid in building_ids}\n",
    "        self.regression_flag = {uid : 0 for uid in building_ids}\n",
    "        self.action_spaces = {uid : a_space for uid, a_space in zip(building_ids, action_spaces)}\n",
    "        self.observation_spaces = {uid : o_space for uid, o_space in zip(building_ids, observation_spaces)}\n",
    "```\n",
    "\n",
    "`[Line 75-83]` Energy size coefficient  for every building (Not Needed in 2022)\n",
    "\n",
    "```python\n",
    "\n",
    "      self.energy_size_coef = {}\n",
    "        self.total_coef = 0\n",
    "        for uid, info in building_info.items():\n",
    "            _coef = info['Annual_DHW_demand (kWh)']/.9 + info['Annual_cooling_demand (kWh)']/3.5 + info['Annual_nonshiftable_electrical_demand (kWh)'] - info['solar_power_capacity (kW)']*8760/6.0\n",
    "            self.energy_size_coef[uid] = max(.3*(_coef + info['solar_power_capacity (kW)']*8760/6.0), _coef)/8760\n",
    "            self.total_coef += self.energy_size_coef[uid]\n",
    "            \n",
    "        for uid in self.energy_size_coef:\n",
    "            self.energy_size_coef[uid] = self.energy_size_coef[uid]/self.total_coef\n",
    "```\n",
    "\n",
    "`[Line 86-111]` __Define Encoder__: Set Regression Learner for every building, define Encoding for every observation (think of it as data column) and set target variable to be removed\n",
    "\n",
    "`[Line 131-145]` __Define Regression Encoder__: for transforming states in regression model\n",
    "\n",
    "`[Line 149-164]` __Solar Capacity (remove variables if no solar PV)__: removes solar radiation related variables for houses without PV\n",
    "\n",
    "`[Line 131-145]` __Define Regression Encoder__: for transforming states in regression model\n",
    "\n",
    "`[Line 167-179]` __PCA for Dimensionality Reduction__: reduce state space dimension\n",
    "\n",
    "`[Line 181-192]` __Initialize Network__: for transforming states in regression model\n",
    "\n",
    "`[Line 195-202]` __Initialize Policy__: for transforming states in regression model\n",
    "\n",
    "\n",
    "## 2. Select Action (MARLISA method or function)\n",
    "\n",
    "- Takes as inputs `states` and `deterministic`\n",
    "    - `states` is the stated of the buildings\n",
    "    - `deterministic` boolean can be true or false\n",
    "\n",
    "`[Line 212-220]` shuffles the action and state order. which building should take the first action. The next  building has to be know so as to be used during information sharing.\n",
    "\n",
    "`**[Line 222-226]` __Initialize coordination variables__: coordination variables are two dimesional for every building. \n",
    "- `Capacity  Dispatched:` This is the toal amont of electricity already dispatched. it is related to the energy size coefficient at every time step\n",
    "- `**Electrical Demand`: Related to the total electricty demand estimated by a prediction algorithm. __Different in Information Sharing and Non Info Sharing Cases__\n",
    "    - computed as `(toal demand - expected demand)/total coeff` for non exploration or non info sharing and as `total_demand/total coeff` for info sharing situations\n",
    "    - `total demand (non info sharing)` increments expected demand at every time step\n",
    "    - `total demand (info sharing)` increments expected demand at every time step with _expected demand of first agent minus expected demand of next agent_\n",
    "    - `expected demand` is the predicted demand at a given time step\n",
    "        - in information sharing expected demand for next agent is `total demand/total coeff`\n",
    "    - `total coeff` is computed at the start  of simulation  for every building\n",
    "\n",
    "`[Line 230-286]` Explore if its exploration period. safe exploration uses rule based coordination.\n",
    "\n",
    "``` python\n",
    "        if explore:\n",
    "            for uid, uid_next, state in zip(_building_ids, _building_ids_next, _states):\n",
    "                if self.safe_exploration:\n",
    "                    multiplier = 0.4\n",
    "                    hour_day = state[2]\n",
    "                    a_dim = len(self.action_spaces[uid].sample())\n",
    "        \n",
    "                    act = [0.0 for _ in range(a_dim)]\n",
    "                    if hour_day >= 7 and hour_day <= 11:\n",
    "                        act = [-0.05 * multiplier for _ in range(a_dim)]\n",
    "                    elif hour_day >= 12 and hour_day <= 15:\n",
    "                        act = [-0.05 * multiplier for _ in range(a_dim)]\n",
    "                    elif hour_day >= 16 and hour_day <= 18:\n",
    "                        act = [-0.11 * multiplier for _ in range(a_dim)]\n",
    "                    elif hour_day >= 19 and hour_day <= 22:\n",
    "                        act = [-0.06 * multiplier for _ in range(a_dim)]\n",
    "\n",
    "                    # Early nightime: store DHW and/or cooling energy\n",
    "                    if hour_day >= 23 and hour_day <= 24:\n",
    "                        act = [0.085 * multiplier for _ in range(a_dim)]\n",
    "                    elif hour_day >= 1 and hour_day <= 6:\n",
    "                        act = [0.1383 * multiplier for _ in range(a_dim)]\n",
    "```\n",
    "\n",
    "`[Line 287-352]` Uses the MARLISA network to learn\n",
    "\n",
    "\n",
    "## 3. Add to Buffer (MARLISA method or function)\n",
    "\n",
    "Takes as input `states, actions, rewards, next_states, done, coordination_vars, coordination_variables_next`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d829c68d7c130ab0dcf1144f823ff07efab4cc3ddb4fbbf92cf6d88500101820"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('CityLearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
